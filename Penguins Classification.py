# -*- coding: utf-8 -*-
"""Penguins_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JyVS6Xn6htWJEJAmahzp-EcS5RcwornN

### Introduzione

Il dataset dei **Pinguini di Palmer** contiene misure biometriche di tre specie di pinguini (Adelie, Gentoo e Chinstrap), osservate su tre isole dell'arcipelago di Palmer, in Antartide.

### Obiettivo del Notebook üêß‚öñÔ∏è

L'obiettivo √® **addestrare un modello di classificazione per prevedere la specie di un pinguino** in base a caratteristiche fisiche come la lunghezza del becco, la profondit√†, la lunghezza delle pinne e la massa corporea.

### Import & Settings
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb

penguins = pd.read_csv('penguins_size.csv')

"""### Statistiche descrittive & Preliminary Analysis"""

print("Prime righe del dataset:")
penguins.head(10)

print("\nInformazioni sul dataset:")
penguins.info()

print("\nValori mancanti:")
penguins.isnull().sum()

print("\nDistribuzione delle specie:")
sns.countplot(x='species', data=penguins)
plt.title('Distribuzione delle Specie')
plt.show()

sns.boxplot(x='species', y='body_mass_g', data=penguins)
plt.title('Distribuzione della massa corporea per specie')
plt.show()

sns.scatterplot(x='culmen_length_mm', y='culmen_depth_mm', hue='species', data=penguins)
plt.title('Lunghezza vs Profondit√† del Becco')
plt.show()

"""### Training Preprocessing"""

df = penguins.dropna()
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['island'] = le.fit_transform(df['island'])
df['species'] = le.fit_transform(df['species'])  # target

X = df.drop('species', axis=1)
y = df['species']

"""### Training"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

log_model = LogisticRegression(max_iter=200)
log_model.fit(X_train, y_train)
log_preds = log_model.predict(X_test)
print("\n[Logistic Regression]")
print(classification_report(y_test, log_preds))
print("Accuratezza:", accuracy_score(y_test, log_preds))

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)
print("\n[Random Forest]")
print(classification_report(y_test, rf_preds))
print("Accuratezza:", accuracy_score(y_test, rf_preds))

xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)
print("\n[XGBoost]")
print(classification_report(y_test, xgb_preds))
print("Accuratezza:", accuracy_score(y_test, xgb_preds))

